# -*- coding: utf-8 -*-
"""product-machine.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mlse9TaqZvj2RfWsNWeCes_FGpqOPugH
"""

import pandas as pd

df = pd.read_json('cameras.json.gz', compression='gzip', lines=True)
df.head()

"""# Explanatory Data Analysis"""

df.label = df.label.astype('object')

df.info()

df.brand_left.value_counts()

# pd.crosstab(data.brand_left, [data.label, data.brand_right])
df.pivot_table(
    columns='brand_left',
    index=['label', 'brand_right'],
    aggfunc='count',
    margins=True
)

"""Cek Apa yang beda di Action Outdoor"""

# Bisa tes 1-5 produk karna diatas ada 5
df[(df.brand_left=='action outdoor')&(df.brand_right=='action outdoor')&(df.label==0)].title_left.iloc[0]

# Bisa tes 1-5 produk karna diatas ada 5
df[(df.brand_left=='action outdoor')&(df.brand_right=='action outdoor')&(df.label==0)].title_right.iloc[0]

# Contoh sample yang sama
print('Sample of Match Product')
temp = df[df.label == 1].sample(1)
print(temp.title_left.iloc[0])
print(temp.title_right.iloc[0], '\n')

print('Sample of Not Match Product')
temp = df[df.label == 0].sample(1)
print(temp.title_left.iloc[0])
print(temp.title_right.iloc[0])

from nltk import ngrams

def find_common(text1, text2, ngram):

  text1 = ngrams(text1.split(), ngram)
  text1 = [' '.join(grams) for grams in text1]

  text2 = ngrams(text2.split(), ngram)
  text2 = [' '.join(grams) for grams in text2]

  common = set(text1).intersection(text2)

  return list(common)

# Cari kata yang sama dari kalimat
find_common('sepatu olahraga indonesia', 'sepatu puma dari indonesia', 2)

temp = df.copy()
temp = temp[['title_left', 'title_right', 'label']]

temp['title_left_len']  = temp.title_left.apply(lambda x: len(x.split()))
temp['title_right_len'] = temp.title_right.apply(lambda x: len(x.split()))
temp['common_words']    = temp.apply(lambda x: find_common(x['title_left'], x['title_right'], 1), axis=1)
temp['common_words_len']= temp.common_words.apply(lambda x: len(x))

temp.describe()

temp.pivot_table(
    columns='label',
    aggfunc='mean',
)

temp[['label', 'common_words_len']].boxplot(by='label', figsize=(10,10))

!git clone https://github.com/amueller/word_cloud.git
!cd word_cloud
!pip install word_cloud/.

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import matplotlib.pyplot as plt

wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white", width=500, height=500)

text = " ".join(title for title in temp.title_left)
show = wordcloud.generate(text)

# Display the generated image:
plt.figure(figsize=(20,10))
plt.imshow(show, interpolation='bilinear')
plt.axis("off")
plt.show()

from sklearn.model_selection import train_test_split

train, test = train_test_split(df, test_size=0.2, random_state=10)

print(len(train), len(test))

import re

def preprocessing(text):
  text = str(text).lower()
  text = re.sub(r'[^\w ]', '', text)
  return text

train['title_left']  = train['title_left'].apply(preprocessing)
train['title_right'] = train['title_right'].apply(preprocessing)
test['title_left']   = test['title_left'].apply(preprocessing)
test['title_right']  = test['title_right'].apply(preprocessing)

"""# TF-IDF"""

train_left_title  = train.title_left.tolist()
train_right_title = train.title_right.tolist()
train_title       = train_left_title+train_right_title
train_labels      = train.label.tolist()
print(len(train_left_title), len(train_right_title), len(train_labels), len(train_title))

test_left_title  = test.title_left.tolist()
test_right_title = test.title_right.tolist()
test_title       = test_left_title+test_right_title
test_labels      = test.label.tolist()
print(len(test_left_title), len(test_right_title), len(test_labels), len(test_title))

# cek masing2 left dan right beserta label nya
train_left_title[0], train_right_title[0], train_labels[0]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def get_similarity(vector):
    cosine_sim_arr = []
    n              = int(len(vector) / 2)
    for i in range(n):
        j             = i + n
        cosine_sim    = cosine_similarity([vector[i]], [vector[j]])
        cosine_sim_arr.append(cosine_sim[0][0])
    return cosine_sim_arr

vectorizer   = TfidfVectorizer()
vectorizer.fit(train_title)

train_vector = vectorizer.transform(train_title).toarray()
test_vector  = vectorizer.transform(test_title).toarray()

# cek hasil train
train_vector[0]

# Misal ada 2 produk, dan memiliki tingkat kesamaan mencapai 70%
# 70% akan dibulatkan menjadi 0 / 1, sesuai dengan threshold yang kita pilih atau di tentukan

from sklearn import metrics

thresh         = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
cosine_sim_arr = np.array(get_similarity(test_vector))
best_value     = (-1, -1)

for thrs in thresh:
    y_pred         = np.where(cosine_sim_arr > thrs, 1, 0)
    x              = metrics.classification_report(y_pred=y_pred, y_true=test_labels, labels=[0, 1], digits=4, output_dict=True)

    if best_value[1] < x['weighted avg']['f1-score']:
      best_value = (thrs, x['weighted avg']['f1-score'])

    print(thrs, x['0']['f1-score'], x['1']['f1-score'], x['weighted avg']['f1-score'])
    print('')

print('best value: ', best_value)



pred_label         = np.where(cosine_sim_arr > best_value[0], 1, 0)

temp               = test[['title_left', 'title_right', 'label']].copy()
temp['pred_label'] = pred_label
temp.head()

def get_status(y_true, y_pred):
  if y_true==1:
    if y_pred==1:
      return 'tp'
    else:
      return 'fn'
  else:
    if y_pred==0:
      return 'tn'
    else:
      return 'fp'


temp['status'] = temp.apply(lambda x: get_status(x['label'], x['pred_label']), axis=1)
temp.head()

pd.set_option('display.max_colwidth', -1)

temp[temp.status == 'tp'].head()

temp[temp.status == 'tn'].head()

temp[temp.status == 'fp'].head()

temp[temp.status == 'fn'].head()



"""# Add more features"""

train.info()

print('Sample of Match Product')
temp = df[df.label == 1].sample(1)
print(temp.description_left.iloc[0])
print(temp.description_right.iloc[0], '\n')

print('Sample of Not Match Product')
temp = df[df.label == 0].sample(1)
print(temp.description_left.iloc[0])
print(temp.description_right.iloc[0])

# Gabung title dan deskripsi
train.description_left    = train.description_left.fillna('')
train.description_right   = train.description_right.fillna('')
train['title_desc_left']  = train.apply(lambda x: x['title_left'] + ' ' + x['description_left'], axis=1)
train['title_desc_right'] = train.apply(lambda x: x['title_right'] + ' ' + x['description_right'], axis=1)

train_left_text           = train.title_desc_left.tolist()
train_right_text          = train.title_desc_right.tolist()
train_text                = train_left_text+train_right_text
train_labels              = train.label.tolist()
print(len(train_left_text), len(train_right_text), len(train_labels), len(train_text))

test.description_left    = test.description_left.fillna('')
test.description_right   = test.description_right.fillna('')
test['title_desc_left']  = test.apply(lambda x: x['title_left'] + ' ' + x['description_left'], axis=1)
test['title_desc_right'] = test.apply(lambda x: x['title_right'] + ' ' + x['description_right'], axis=1)

test_left_text          = test.title_desc_left.tolist()
test_right_text         = test.title_desc_right.tolist()
test_text               = test_left_text+test_right_text
test_labels             = test.label.tolist()
print(len(test_left_text), len(test_right_text), len(test_labels), len(test_text))

train_left_text[0], train_right_text[0], train_labels[0]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def get_similarity(vector):
    cosine_sim_arr = []
    n              = int(len(vector) / 2)
    for i in range(n):
        j             = i + n
        cosine_sim    = cosine_similarity([vector[i]], [vector[j]])
        cosine_sim_arr.append(cosine_sim[0][0])
    return cosine_sim_arr

vectorizer   = TfidfVectorizer()
vectorizer.fit(train_text)

train_vector = vectorizer.transform(train_text).toarray()
test_vector  = vectorizer.transform(test_text).toarray()

train_vector[0]

from sklearn import metrics

thresh         = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
cosine_sim_arr = np.array(get_similarity(test_vector))
best_value     = (-1, -1)

for thrs in thresh:
    y_pred         = np.where(cosine_sim_arr > thrs, 1, 0)
    x              = metrics.classification_report(y_pred=y_pred, y_true=test_labels, labels=[0, 1], digits=4, output_dict=True)

    if best_value[1] < x['weighted avg']['f1-score']:
      best_value = (thrs, x['weighted avg']['f1-score'])

    print(thrs, x['0']['f1-score'], x['1']['f1-score'], x['weighted avg']['f1-score'])
    print('')

print('best value: ', best_value)

"""# Experiment with Another Preprocessing"""

import re

def preprocessing(text):
  text = str(text).lower()
  text = re.sub(r'[^\w ]', '', text)
  text = re.sub(r'([0-9])([a-z])', r'\1 \2', text)
  text = re.sub(r'([a-z])([0-9])', r'\1 \2', text)
  return text

preprocessing('Camera A53VV 100gb')

train['title_left']  = train['title_left'].apply(preprocessing)
train['title_right'] = train['title_right'].apply(preprocessing)
test['title_left']   = test['title_left'].apply(preprocessing)
test['title_right']  = test['title_right'].apply(preprocessing)

train_left_title  = train.title_left.tolist()
train_right_title = train.title_right.tolist()
train_title       = train_left_title+train_right_title
train_labels      = train.label.tolist()
print(len(train_left_title), len(train_right_title), len(train_labels), len(train_title))

test_left_title  = test.title_left.tolist()
test_right_title = test.title_right.tolist()
test_title       = test_left_title+test_right_title
test_labels      = test.label.tolist()
print(len(test_left_title), len(test_right_title), len(test_labels), len(test_title))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def get_similarity(vector):
    cosine_sim_arr = []
    n              = int(len(vector) / 2)
    for i in range(n):
        j             = i + n
        cosine_sim    = cosine_similarity([vector[i]], [vector[j]])
        cosine_sim_arr.append(cosine_sim[0][0])
    return cosine_sim_arr

vectorizer   = TfidfVectorizer()
vectorizer.fit(train_title)

train_vector = vectorizer.transform(train_title).toarray()
test_vector  = vectorizer.transform(test_title).toarray()

from sklearn import metrics

thresh         = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
cosine_sim_arr = np.array(get_similarity(test_vector))
best_value     = (-1, -1)

for thrs in thresh:
    y_pred         = np.where(cosine_sim_arr > thrs, 1, 0)
    x              = metrics.classification_report(y_pred=y_pred, y_true=test_labels, labels=[0, 1], digits=4, output_dict=True)

    if best_value[1] < x['weighted avg']['f1-score']:
      best_value = (thrs, x['weighted avg']['f1-score'])

    print(thrs, x['0']['f1-score'], x['1']['f1-score'], x['weighted avg']['f1-score'])
    print('')

print('best value: ', best_value)

